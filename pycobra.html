

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pycobra package &mdash; pycobra 0.2.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="pycobra 0.2.2 documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> pycobra
          

          
          </a>

          
            
            
              <div class="version">
                0.2.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">pycobra package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-pycobra.classifiercobra">pycobra.classifiercobra module</a></li>
<li><a class="reference internal" href="#module-pycobra.cobra">pycobra.cobra module</a></li>
<li><a class="reference internal" href="#module-pycobra.diagnostics">pycobra.diagnostics module</a></li>
<li><a class="reference internal" href="#module-pycobra.ewa">pycobra.ewa module</a></li>
<li><a class="reference internal" href="#module-pycobra.visualisation">pycobra.visualisation module</a></li>
<li><a class="reference internal" href="#module-pycobra">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pycobra</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>pycobra package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/pycobra.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pycobra-package">
<h1>pycobra package<a class="headerlink" href="#pycobra-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pycobra.classifiercobra">
<span id="pycobra-classifiercobra-module"></span><h2>pycobra.classifiercobra module<a class="headerlink" href="#module-pycobra.classifiercobra" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pycobra.classifiercobra.ClassifierCobra">
<em class="property">class </em><code class="descclassname">pycobra.classifiercobra.</code><code class="descname">ClassifierCobra</code><span class="sig-paren">(</span><em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Classification algorithm as introduced by
Mojirsheibani [1999] Combining Classifiers via Discretization,
Journal of the American Statistical Association.</p>
<dl class="docutils">
<dt>random_state: integer or a numpy.random.RandomState object.</dt>
<dd>Set the state of the random number generator to pass on to shuffle and loading machines, to ensure
reproducibility of your experiments, for example.</dd>
</dl>
<dl class="docutils">
<dt>machines: A dictionary which maps machine names to the machine objects.</dt>
<dd>The machine object must have a predict method for it to be used during aggregation.</dd>
<dt>machine_predictions: A dictionary which maps machine name to it’s predictions over X_l</dt>
<dd>This value is used to determine which points from y_l are used to aggregate.</dd>
</dl>
<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>default=True</em>, <em>X_k=None</em>, <em>X_l=None</em>, <em>y_k=None</em>, <em>y_l=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>X: array-like, [n_samples, n_features]</dt>
<dd>Training data which will be used to create ClassifierCobra.</dd>
<dt>y: array-like [n_samples]</dt>
<dd>Training labels for classification.</dd>
<dt>default: bool, optional</dt>
<dd>If set as true then sets up COBRA with default machines and splitting.</dd>
<dt>X_k <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Training data which is used to train the machines loaded into COBRA.</dd>
<dt>y_k <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values used to train the machines loaded into COBRA.</dd>
<dt>X_l <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Training data which is used during the aggregation of COBRA.</dd>
<dt>y_l <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values which are actually used in the aggregation of COBRA.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.load_default">
<code class="descname">load_default</code><span class="sig-paren">(</span><em>machine_list=['sgd', 'tree', 'knn', 'svm']</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.load_default" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads 4 different scikit-learn regressors by default.</p>
<dl class="docutils">
<dt>machine_list: optional, list of strings</dt>
<dd>List of default machine names to be loaded.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.load_machine">
<code class="descname">load_machine</code><span class="sig-paren">(</span><em>machine_name</em>, <em>machine</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.load_machine" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a machine to be used during the aggregation strategy.
The machine object must have been trained using X_k and y_k, and must have a ‘predict()’ method.
After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.</p>
<dl class="docutils">
<dt>machine_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>Name of the machine you are loading</dd>
<dt>machine: machine/regressor object</dt>
<dd>The regressor machine object which is mapped to the machine_name</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.load_machine_predictions">
<code class="descname">load_machine_predictions</code><span class="sig-paren">(</span><em>predictions=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.load_machine_predictions" title="Permalink to this definition">¶</a></dt>
<dd><p>Stores the trained machines’ predicitons on D_l in a dictionary, to be used for predictions.
Should be run after all the machines to be used for aggregation is loaded.</p>
<dl class="docutils">
<dt>predictions: dictionary, optional</dt>
<dd>A pre-existing machine:predictions dictionary can also be loaded.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.pred">
<code class="descname">pred</code><span class="sig-paren">(</span><em>X</em>, <em>M</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.pred" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the CLassififerCobra aggregation scheme, used in predict method.</p>
<p>X: array-like, [n_features]</p>
<dl class="docutils">
<dt>M: int, optional</dt>
<dd>M refers to the number of machines the prediction must be close to to be considered during aggregation.</dd>
<dt>info: boolean, optional</dt>
<dd>If info is true the list of points selected in the aggregation is returned.</dd>
</dl>
<p>result: prediction</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>M=None</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the ClassifierCobra aggregation scheme, calls pred.
ClassifierCobra performs a majority vote among all points which are retained by the COBRA procedure.</p>
<p>X: array-like, [n_features]</p>
<dl class="docutils">
<dt>M: int, optional</dt>
<dd>M refers to the number of machines the prediction must be close to to be considered during aggregation.</dd>
<dt>info: boolean, optional</dt>
<dd>If info is true the list of points selected in the aggregation is returned.</dd>
</dl>
<p>result: prediction</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.classifiercobra.ClassifierCobra.split_data">
<code class="descname">split_data</code><span class="sig-paren">(</span><em>k=None</em>, <em>l=None</em>, <em>shuffle_data=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.classifiercobra.ClassifierCobra.split_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the data into different parts for training machines and for aggregation.</p>
<dl class="docutils">
<dt>k <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>k is the number of points used to train the machines.
Those are the first k points of the data provided.</dd>
<dt>l: int, optional</dt>
<dd>l is the number of points used to form the ClassifierCobra aggregate.</dd>
<dt>shuffle: bool, optional</dt>
<dd>Boolean value to decide to shuffle the data before splitting.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pycobra.cobra">
<span id="pycobra-cobra-module"></span><h2>pycobra.cobra module<a class="headerlink" href="#module-pycobra.cobra" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pycobra.cobra.Cobra">
<em class="property">class </em><code class="descclassname">pycobra.cobra.</code><code class="descname">Cobra</code><span class="sig-paren">(</span><em>random_state=None</em>, <em>epsilon=None</em>, <em>machines=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>COBRA: A combined regression strategy.
Based on the paper by Biau, Fischer, Guedj, Malley [2016].
This is a pythonic implementation of the original COBRA code.</p>
<dl class="docutils">
<dt>random_state: integer or a numpy.random.RandomState object.</dt>
<dd>Set the state of the random number generator to pass on to shuffle and loading machines, to ensure
reproducibility of your experiments, for example.</dd>
<dt>epsilon: float, optional</dt>
<dd>Epsilon value described in the paper which determines which points are selected for the aggregate.
Default value is determined by optimizing over a grid if test data is provided.
If not, a mean of the possible distances is chosen.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">machines_</span></a>: A dictionary which maps machine names to the machine objects.</dt>
<dd>The machine object must have a predict method for it to be used during aggregation.</dd>
<dt><a href="#id3"><span class="problematic" id="id4">machine_predictions_</span></a>: A dictionary which maps machine name to it’s predictions over X_l</dt>
<dd>This value is used to determine which points from y_l are used to aggregate.</dd>
</dl>
<p><a href="#id5"><span class="problematic" id="id6">all_predictions_</span></a>: numpy array with all the predictions, to be used for epsilon manipulation.</p>
<dl class="method">
<dt id="pycobra.cobra.Cobra.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>default=True</em>, <em>X_k=None</em>, <em>X_l=None</em>, <em>y_k=None</em>, <em>y_l=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>X: array-like, [n_samples, n_features]</dt>
<dd>Training data which will be used to create the COBRA aggregate.</dd>
<dt>y: array-like, shape = [n_samples]</dt>
<dd>Target values used to train the machines used in the aggregation.</dd>
<dt>default: bool, optional</dt>
<dd>If set as true then sets up COBRA with default machines and splitting.</dd>
<dt>X_k <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Training data which is used to train the machines used in the aggregation.
Can be loaded directly into COBRA; if not, the split_data method is used as default.</dd>
<dt>y_k <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values used to train the machines used in the aggregation.</dd>
<dt>X_l <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Training data which is used to form the aggregate.
Can be loaded directly into COBRA; if not, the split_data method is used as default.</dd>
<dt>y_l <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values which are actually used to form the aggregate.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.load_default">
<code class="descname">load_default</code><span class="sig-paren">(</span><em>machine_list=['lasso', 'tree', 'ridge', 'random_forest']</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.load_default" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads 4 different scikit-learn regressors by default.</p>
<dl class="docutils">
<dt>machine_list: optional, list of strings</dt>
<dd>List of default machine names to be loaded.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.load_machine">
<code class="descname">load_machine</code><span class="sig-paren">(</span><em>machine_name</em>, <em>machine</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.load_machine" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a machine to be used during the aggregation strategy.
The machine object must have been trained using X_k and y_k, and must have a ‘predict()’ method.
After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.</p>
<dl class="docutils">
<dt>machine_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>Name of the machine you are loading</dd>
<dt>machine: machine/regressor object</dt>
<dd>The regressor machine object which is mapped to the machine_name</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.load_machine_predictions">
<code class="descname">load_machine_predictions</code><span class="sig-paren">(</span><em>predictions=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.load_machine_predictions" title="Permalink to this definition">¶</a></dt>
<dd><p>Stores the trained machines’ predicitons on training data in a dictionary, to be used for predictions.
Should be run after all the machines to be used for aggregation is loaded.</p>
<dl class="docutils">
<dt>predictions: dictionary, optional</dt>
<dd>A pre-existing machine:predictions dictionary can also be loaded.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.pred">
<code class="descname">pred</code><span class="sig-paren">(</span><em>X</em>, <em>alpha</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.pred" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the COBRA aggregation scheme, used in predict method.</p>
<p>X: array-like, [n_features]</p>
<dl class="docutils">
<dt>alpha: int, optional</dt>
<dd>alpha refers to the number of machines the prediction must be close to to be considered during aggregation.</dd>
<dt>info: boolean, optional</dt>
<dd>If info is true the list of points selected in the aggregation is returned.</dd>
</dl>
<p>avg: prediction</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>alpha=None</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the COBRA aggregation scheme, calls pred.</p>
<p>X: array-like, [n_features]</p>
<dl class="docutils">
<dt>alpha: int, optional</dt>
<dd>alpha refers to the number of machines the prediction must be close to to be considered during aggregation.</dd>
<dt>info: boolean, optional</dt>
<dd>If info is true the list of points selected in the aggregation is returned.</dd>
</dl>
<p>result: prediction</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.set_epsilon">
<code class="descname">set_epsilon</code><span class="sig-paren">(</span><em>X_epsilon=None</em>, <em>y_epsilon=None</em>, <em>grid_points=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.set_epsilon" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>X_epsilon <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Used if no epsilon is passed to find the optimal epsilon for data passed.</dd>
<dt>y_epsilon <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Used if no epsilon is passed to find the optimal epsilon for data passed.</dd>
<dt>grid_points: int, optional</dt>
<dd>If no epsilon value is passed, this parameter controls how many points on the grid to traverse.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.cobra.Cobra.split_data">
<code class="descname">split_data</code><span class="sig-paren">(</span><em>k=None</em>, <em>l=None</em>, <em>shuffle_data=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.cobra.Cobra.split_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the data into different parts for training machines and for aggregation.</p>
<dl class="docutils">
<dt>k <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>k is the number of points used to train the machines.
Those are the first k points of the data provided.</dd>
<dt>l: int, optional</dt>
<dd>l is the number of points used to form the COBRA aggregate.</dd>
<dt>shuffle: bool, optional</dt>
<dd>Boolean value to decide to shuffle the data before splitting.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pycobra.diagnostics">
<span id="pycobra-diagnostics-module"></span><h2>pycobra.diagnostics module<a class="headerlink" href="#module-pycobra.diagnostics" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pycobra.diagnostics.Diagnostics">
<em class="property">class </em><code class="descclassname">pycobra.diagnostics.</code><code class="descname">Diagnostics</code><span class="sig-paren">(</span><em>aggregate</em>, <em>X_test=None</em>, <em>y_test=None</em>, <em>load_MSE=True</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Optimization of hyperparameters, and error details.</p>
<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.load_MSE">
<code class="descname">load_MSE</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.load_MSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes MSE and error bound for each Machine based on test data.</p>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.load_errors">
<code class="descname">load_errors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.load_errors" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes accuracy score for each Machine based on test data.</p>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_alpha">
<code class="descname">optimal_alpha</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>single=False</em>, <em>epsilon=None</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal alpha for testing data for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want optimal alpha values</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>single: boolean, optional</dt>
<dd>Option to calculate optimal alpha for a single query point instead.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each alpha value</dd>
<dt>epsilon: float, optional</dt>
<dd>fixed epsilon value to help determine optimal alpha.</dd>
</dl>
<p>MSE: dictionary mapping alpha with mean squared errors
opt: optimal alpha combination</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_alpha_grid">
<code class="descname">optimal_alpha_grid</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>line_points=200</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_alpha_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal epsilon and alpha for a single query point for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want optimal alpha and epsilon values</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>line_points: integer, optional</dt>
<dd>Number of epsilon values to traverse the grid.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each epsilon/alpha value</dd>
</dl>
<p>MSE: dictionary mapping (alpha, epsilon) with mean squared errors
opt: optimal epislon/alpha combination</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_beta">
<code class="descname">optimal_beta</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>betas=None</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal beta value for the Ewa predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want for optimal beta.</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>betas: list, optional</dt>
<dd>List of beta values to iterate over for optimal beta.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each beta value.</dd>
</dl>
<p>MSE: dictionary mapping epsilon with mean squared errors
opt: optimal beta value</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_epsilon">
<code class="descname">optimal_epsilon</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>line_points=200</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_epsilon" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal epsilon value for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want for optimal epsilon.</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>line_points: integer, optional</dt>
<dd>Number of epsilon values to traverse the grid.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each epsilon value.</dd>
</dl>
<p>MSE: dictionary mapping epsilon with mean squared errors
opt: optimal epsilon value</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_machines">
<code class="descname">optimal_machines</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>single=False</em>, <em>epsilon=None</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_machines" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal combination of machines for testing data for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want optimal machine combinations.</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>single: boolean, optional</dt>
<dd>Option to calculate optimal machine combinations for a single query point instead.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each machine combination value</dd>
<dt>epsilon: float, optional</dt>
<dd>fixed epsilon value to help determine optimal machines.</dd>
</dl>
<p>MSE: dictionary mapping machines with mean squared errors
opt: optimal machines combination</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_machines_grid">
<code class="descname">optimal_machines_grid</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>line_points=200</em>, <em>info=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_machines_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal epsilon and machine-combination for a single query point for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want optimal machines and epsilon values</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>line_points: integer, optional</dt>
<dd>Number of epsilon values to traverse the grid.</dd>
<dt>info: bool, optional</dt>
<dd>Returns MSE dictionary for each epsilon/machine value.</dd>
</dl>
<p>MSE: dictionary mapping (machine combination, epsilon) with mean squared errors
opt: optimal epislon/machine combination</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.diagnostics.Diagnostics.optimal_split">
<code class="descname">optimal_split</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>split=None</em>, <em>epsilon=None</em>, <em>info=False</em>, <em>graph=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.diagnostics.Diagnostics.optimal_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the optimal combination split (D_k, D_l) for fixed epsilon value for the COBRA predictor.</p>
<dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Vector for which we want for optimal split.</dd>
<dt>y: float</dt>
<dd>Target value for query to compare.</dd>
<dt>epsilon: float, optional.</dt>
<dd>fixed epsilon value to help determine optimal machines.</dd>
<dt>split: list, optional.</dt>
<dd>D_k, D_l break-up to calculate MSE</dd>
<dt>info: bool, optional.</dt>
<dd>Returns MSE dictionary for each split.</dd>
<dt>graph: bool, optional.</dt>
<dd>Plots graph of MSE vs split</dd>
</dl>
<p>MSE: dictionary mapping split with mean squared errors
opt: optimal epsilon value</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pycobra.ewa">
<span id="pycobra-ewa-module"></span><h2>pycobra.ewa module<a class="headerlink" href="#module-pycobra.ewa" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pycobra.ewa.Ewa">
<em class="property">class </em><code class="descclassname">pycobra.ewa.</code><code class="descname">Ewa</code><span class="sig-paren">(</span><em>random_state=None</em>, <em>beta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Exponential Weighted Average aggregation method.
Implementation based on work by:
M. Mojirsheibani (1999), Combining Classifiers via Discretization,
Journal of the American Statistical Association.</p>
<dl class="docutils">
<dt>random_state: integer or a numpy.random.RandomState object.</dt>
<dd>Set the state of the random number generator to pass on to shuffle and loading machines, to ensure
reproducibility of your experiments, for example.</dd>
<dt>beta: float, optional</dt>
<dd>Parameter to be passed when creating machine weights for EWA.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id7"><span class="problematic" id="id8">machines_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd>dictionary mapping name of machine to the object.</dd>
<dt><a href="#id9"><span class="problematic" id="id10">machine_predictions_</span></a>: A dictionary which maps machine name to it’s predictions over X_l</dt>
<dd>This value is used to determine which points from y_l are used to aggregate.</dd>
</dl>
<dl class="method">
<dt id="pycobra.ewa.Ewa.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>default=True</em>, <em>X_k=None</em>, <em>X_l=None</em>, <em>y_k=None</em>, <em>y_l=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>X: array-like, [n_features]</dt>
<dd>Training data which will be used to create the EWA aggregate.</dd>
<dt>y: array-like, shape = [n_samples]</dt>
<dd>Target values used to train the machines used in the EWA aggregate.</dd>
<dt>default: bool, optional</dt>
<dd>If set as true then sets up EWA with default machines and splitting.</dd>
<dt>X_k <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features], optional</span></dt>
<dd>Training data which is used to train the machines loaded into Ewa.
Can be loaded directly into EWA; if not, the split_data method is used as default.</dd>
<dt>y_k <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Target values used to train the machines loaded into EWA.</dd>
<dt>X_l <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features], optional</span></dt>
<dd>Training data which is used during the aggregation of EWA.
Can be loaded directly into EWA; if not, the split_data method is used as default.</dd>
<dt>y_l <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Target values which are actually used in the aggregation of EWA.</dd>
</dl>
<p>self : returns an instance of self.</p>
<p>We store the data used to train the machines because this information is used to make the prediction.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.load_default">
<code class="descname">load_default</code><span class="sig-paren">(</span><em>machine_list=['lasso', 'tree', 'ridge', 'random_forest']</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.load_default" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads 4 different scikit-learn regressors by default.</p>
<dl class="docutils">
<dt>machine_list: optional, list of strings</dt>
<dd>List of default machine names to be loaded.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.load_machine">
<code class="descname">load_machine</code><span class="sig-paren">(</span><em>machine_name</em>, <em>machine</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.load_machine" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a machine to be used during the aggregation strategy.
The machine object must have been trained using X_k and y_k, and must have a ‘predict()’ method.
After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.</p>
<dl class="docutils">
<dt>machine_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>Name of the machine you are loading</dd>
<dt>machine: machine/regressor object</dt>
<dd>The regressor machine object which is mapped to the machine_name</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.load_machine_weights">
<code class="descname">load_machine_weights</code><span class="sig-paren">(</span><em>beta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.load_machine_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads the EWA weights for each machine based on the training data.
Should be run after all the machines to be used for aggregation is loaded.</p>
<dl class="docutils">
<dt>beta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Inverse temperature parameter to form the weights.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.plot_machine_weights">
<code class="descname">plot_machine_weights</code><span class="sig-paren">(</span><em>figsize=8</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.plot_machine_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot each machine weights</p>
<dl class="docutils">
<dt>figsize: float, optional</dt>
<dd>Size of plot.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>X: array-like, [n_features]</p>
<p>result: returns prediction</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.set_beta">
<code class="descname">set_beta</code><span class="sig-paren">(</span><em>X_beta=None</em>, <em>y_beta=None</em>, <em>betas=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.set_beta" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>betas: list, optional</dt>
<dd>List of betas to find optimal beta for weights</dd>
<dt>X_beta <span class="classifier-delimiter">:</span> <span class="classifier">shape = [n_samples, n_features]</span></dt>
<dd>Used if no beta is passed to find the optimal beta for data passed.</dd>
<dt>y_beta <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Used if no beta is passed to find the optimal beta for data passed.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.ewa.Ewa.split_data">
<code class="descname">split_data</code><span class="sig-paren">(</span><em>k=None</em>, <em>l=None</em>, <em>shuffle_data=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.ewa.Ewa.split_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the data into different parts for training machines and for aggregation.</p>
<dl class="docutils">
<dt>k <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>k is the number of points used to train the machines.
Those are the first k points of the data provided.</dd>
<dt>l: int, optional</dt>
<dd>l is the number of points used to form the EWA aggregate.</dd>
<dt>shuffle: bool, optional</dt>
<dd>Boolean value to decide to shuffle the data before splitting.</dd>
</dl>
<p>self : returns an instance of self.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pycobra.visualisation">
<span id="pycobra-visualisation-module"></span><h2>pycobra.visualisation module<a class="headerlink" href="#module-pycobra.visualisation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pycobra.visualisation.Visualisation">
<em class="property">class </em><code class="descclassname">pycobra.visualisation.</code><code class="descname">Visualisation</code><span class="sig-paren">(</span><em>aggregate</em>, <em>X_test</em>, <em>y_test</em>, <em>plot_size=8</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Plots and visualisations of COBRA aggregates.
If X_test and y_test is loaded, you can run the plotting functions with no parameters.</p>
<dl class="method">
<dt id="pycobra.visualisation.Visualisation.QQ">
<code class="descname">QQ</code><span class="sig-paren">(</span><em>machine='COBRA'</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.QQ" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots the machine results vs the actual results in the form of a QQ-plot.</p>
<dl class="docutils">
<dt>machine: string, optional</dt>
<dd>Name of machine to perform QQ-plot.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.visualisation.Visualisation.boxplot">
<code class="descname">boxplot</code><span class="sig-paren">(</span><em>reps=100</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.boxplot" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots boxplots of machines.</p>
<dl class="docutils">
<dt>reps: int, optional</dt>
<dd>Number of times to repeat experiments for boxplot.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.visualisation.Visualisation.color_cobra">
<code class="descname">color_cobra</code><span class="sig-paren">(</span><em>X_test=None, y_test=None, line_points=200, epsilon=None, indice_info=None, plot_machines=['ridge', 'lasso', 'random_forest', 'tree'], single=False, machine_colors=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.color_cobra" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the input space and color query points based on the optimal machine used for that point.</p>
<dl class="docutils">
<dt>epsilon: float, optional</dt>
<dd>Epsilon value to use for diagnostics. Used to find indice_info if it isn’t passed.</dd>
<dt>line_points: int, optional</dt>
<dd>if epsilon is not passed, optimal epsilon is found per point. Used to find indice_info if it isn’t passed.</dd>
<dt>indice_info: dicitonary, optional</dt>
<dd>dictionary mapping indice to optimal machines.</dd>
<dt>plot_machines: list, optional</dt>
<dd>list of machines to be plotted.</dd>
<dt>single: bool, optional</dt>
<dd>plots a single plot with each machine combination.</dd>
<dt>machine_colors: dictionary, optional</dt>
<dd>Depending on the kind of coloring, a dictionary mapping machines to colors.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.visualisation.Visualisation.indice_info">
<code class="descname">indice_info</code><span class="sig-paren">(</span><em>X_test=None</em>, <em>y_test=None</em>, <em>epsilon=None</em>, <em>line_points=200</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.indice_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to return information about each indices (query) optimal machines for testing data.</p>
<dl class="docutils">
<dt>epsilon: float, optional</dt>
<dd>Epsilon value to use for diagnostics</dd>
<dt>line_points: int, optional</dt>
<dd>if epsilon is not passed, optimal epsilon is found per point.</dd>
</dl>
<p>indice_info: dicitonary mapping indice to optimal machines.</p>
<p>MSE: dictionary mapping indice to mean squared error for optimal machines for that point.</p>
</dd></dl>

<dl class="method">
<dt id="pycobra.visualisation.Visualisation.plot_machines">
<code class="descname">plot_machines</code><span class="sig-paren">(</span><em>machines=None</em>, <em>colors=None</em>, <em>plot_indices=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.plot_machines" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the results of the machines versus the actual answers (testing space).</p>
<dl class="docutils">
<dt>machines: list, optional</dt>
<dd>List of machines to plot.</dd>
<dt>colors: list, optional</dt>
<dd>Colors of machines.</dd>
<dt>plot_indices: boolean, optional.</dt>
<dd>Plots truth values against indices.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pycobra.visualisation.Visualisation.voronoi">
<code class="descname">voronoi</code><span class="sig-paren">(</span><em>X_test=None, y_test=None, line_points=200, epsilon=None, indice_info=None, MSE=None, plot_machines=['ridge', 'lasso', 'random_forest', 'tree'], machine_colors=None, gradient=False, single=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.Visualisation.voronoi" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the input space and color query points as a Voronoi Tesselation based on the optimal machine used for that point.</p>
<dl class="docutils">
<dt>epsilon: float, optional</dt>
<dd>Epsilon value to use for diagnostics. Used to find indice_info if it isn’t passed.</dd>
<dt>line_points: int, optional</dt>
<dd>if epsilon is not passed, optimal epsilon is found per point. Used to find indice_info if it isn’t passed.</dd>
<dt>indice_info: dicitonary, optional</dt>
<dd>dictionary mapping indice to optimal machines.</dd>
<dt>MSE: dictionary, optional</dt>
<dd>dictionary mapping indice to mean-squared error for optimal machines</dd>
<dt>plot_machines: list, optional</dt>
<dd>list of machines to be plotted.</dd>
<dt>single: bool, optional</dt>
<dd>plots a single plot with each machine combination.</dd>
<dt>gradient: bool, optional</dt>
<dd>instead of aggregating optimal machines, plots a colored plot for each machine,
shaded according to the mean-squared error of that “region”</dd>
<dt>machine_colors: dictionary, optional</dt>
<dd>Depending on the kind of coloring, a dictionary mapping machines to colors.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pycobra.visualisation.create_labels">
<code class="descclassname">pycobra.visualisation.</code><code class="descname">create_labels</code><span class="sig-paren">(</span><em>indice_info</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.create_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to create labels for plotting.</p>
<dl class="docutils">
<dt>indice_info: list of strings</dt>
<dd>List of machine names</dd>
</dl>
<dl class="docutils">
<dt>label: string</dt>
<dd>Serves as a label during plotting.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pycobra.visualisation.gen_machine_colors">
<code class="descclassname">pycobra.visualisation.</code><code class="descname">gen_machine_colors</code><span class="sig-paren">(</span><em>only_colors=False</em>, <em>num_colors=None</em>, <em>indice_info=None</em>, <em>rgb=False</em>, <em>plot_machines=None</em>, <em>colors=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.gen_machine_colors" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to create a machine combinations to color dictionary, or a list of colors.</p>
<dl class="docutils">
<dt>indice_info: dictionary, optional</dt>
<dd>Dictionary which is a result of running pycobra.visualisation.indice_info. Maps indices to combinations of machines.</dd>
<dt>only_colors: bool, optional</dt>
<dd>Option to return only a list of colors</dd>
<dt>num_colors: int, optional</dt>
<dd>Number of colors to be returned if using only_colors</dd>
<dt>rgb <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd>Creates dictionary based on machine used and r, g, b, a scheme.</dd>
<dt>plot_machines: list of strings, optional</dt>
<dd>List of machines to use in rgb coloring.</dd>
<dt>colors: list of strings, optional</dt>
<dd>List of colors to be used for pairing with machine_combinations</dd>
</dl>
<dl class="docutils">
<dt>machine_colors: dictionary</dt>
<dd>Dictionary mapping machine combinations and color.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pycobra.visualisation.voronoi_finite_polygons_2d">
<code class="descclassname">pycobra.visualisation.</code><code class="descname">voronoi_finite_polygons_2d</code><span class="sig-paren">(</span><em>vor</em>, <em>radius=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pycobra.visualisation.voronoi_finite_polygons_2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Code originally written by pv: <a class="reference external" href="https://gist.github.com/pv/8036995">https://gist.github.com/pv/8036995</a>.
Helper method for voronoi.
Reconstruct infinite voronoi regions in a 2D diagram to finite
regions.</p>
<dl class="docutils">
<dt>vor <span class="classifier-delimiter">:</span> <span class="classifier">Voronoi</span></dt>
<dd>Input diagram</dd>
<dt>radius <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd>Distance to ‘points at infinity’.</dd>
</dl>
<dl class="docutils">
<dt>regions <span class="classifier-delimiter">:</span> <span class="classifier">list of tuples</span></dt>
<dd>Indices of vertices in each revised Voronoi regions.</dd>
<dt>vertices <span class="classifier-delimiter">:</span> <span class="classifier">list of tuples</span></dt>
<dd>Coordinates for revised Voronoi vertices. Same as coordinates
of input vertices, with ‘points at infinity’ appended to the
end.</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pycobra">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pycobra" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Bhargav Srinivasa Desikan, Benjamin Guedj.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.2.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>